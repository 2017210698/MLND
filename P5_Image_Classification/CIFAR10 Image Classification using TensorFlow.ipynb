{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# CIFAR10 Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一章 CIFAR10 上手"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CIFAR10 数据集概述\n",
    "\n",
    "- 总计 60000 张图片。其中 50000 张用于训练，10000 张用于测试。\n",
    "- 所有图片的尺寸统一为 32 x 32 x 3\n",
    "- 图片的内容标签分为 10 类，每张图片的标签唯一。\n",
    "- 每一类图片的个数都是 6000 张。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CIFAR10 数据集分析\n",
    "\n",
    "- 图片尺寸全部统一，因此无需对图片尺寸进行 resize。\n",
    "- 每一个标签的数据量相等，因此整个数据集是平衡的（Balanced），不存在非平衡数据集的训练问题。\n",
    "- 数据集很庞大，有六万张照片，不存在小数据集训练的过拟合问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CIFAR10 数据集格式\n",
    "\n",
    "- 压缩包里含有 6 个 Pickle 文件，其中 5 个 `data_batch` 是训练集，单独一个 `test_batch` 是测试集。\n",
    "- 用 `pickle.load()` 将所有文件中的数据都读入内存\n",
    "\n",
    "\n",
    "- 每个 Pickle 文件都含有 10000 张图片及其展示的内容标签。Pickle 文件所包含的对象是一个词典，该词典有如下4个键：\n",
    "    - data：图像像素数据，np.array 类型\n",
    "    - labels：图像内容标签，list 类型\n",
    "    - filenames：原始图像的文件名（目前用不上）\n",
    "    - batch_label：数据所属的训练集编号（没什么用）\n",
    "    \n",
    "    \n",
    "- data 是一个尺寸为 (10000, 3072) 的 Numpy 数组\n",
    "    - 每一行是一张图片的所有像素，长度为3072\n",
    "    - 每张图片的尺寸是32x32=1024，其三个颜色通道串联接在一起，即 1024,1024,1024\n",
    "    - 需要将每张尺寸为 (1, 3072) 的图片还原为正常的图像尺寸 (32, 32, 3)\n",
    "    - 由于考虑到目前第一维只能是颜色通道，因此应该先将其 reshape(3, 32, 32), 再用 transpose 把颜色通道交换至最后一个维度。\n",
    "    \n",
    "\n",
    "- labels 是一个长度为 10000 的 list，表示图像的实际内容类别，取值为 [0, 9]，其涵义如下：\n",
    "    - 0 = airplane\t\t\t\t\t\t\t\t\t\t\n",
    "    - 1 = automobile\t\t\t\t\t\t\t\t\t\t\n",
    "    - 2 = bird\t\t\t\t\t\t\t\t\t\t\n",
    "    - 3 = cat\t\t\t\t\t\t\t\t\t\t\n",
    "    - 4 = deer\t\t\t\t\t\t\t\t\t\t\n",
    "    - 5 = dog\t\t\t\t\t\t\t\t\t\t\n",
    "    - 6 = frog\t\t\t\t\t\t\t\t\t\t\n",
    "    - 7 = horse\t\t\t\t\t\t\t\t\t\t\n",
    "    - 8 = ship\t\t\t\t\t\t\t\t\t\t\n",
    "    - 9 = truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'cifar-10-batches-py//'\n",
    "p = pickle.load(open(path + 'data_batch_1', 'rb'), encoding='bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([b'data', b'labels', b'filenames', b'batch_label'])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, list)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = p[b'data']\n",
    "labels = p[b'labels']\n",
    "type(data), type(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 3072), 10000)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, len(lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nD9l1pU8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2baed5de7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 看第一张图片的样子\n",
    "pic = np.random.choice(range(10000))\n",
    "img = data[pic].reshape(3, 32, 32)    # 先以颜色通道为大，分离出三个颜色通道\n",
    "img = np.transpose(img, (1, 2, 0))    # 然后将颜色通道维度从原来的第0维换至最后一维\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. CIFAR10 数据集预处理\n",
    "\n",
    "- 合并全部 50000 张训练图片及其标签\n",
    "- 将像素灰度值归一化\n",
    "- 将标签进行 One-Hot 编码，以供后期使用 Softmax 进行预测\n",
    "- 导出经过预处理后的训练数据为 Pickle 文件，方便以后直接调用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 合并全部 50000 张训练图片及其标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 先申请一块完整的内存，然后再用循环慢慢将这块内存填满，这样比不断追加的方案内存效率高得多\n",
    "X = np.zeros((50000, 32, 32, 3), dtype=np.uint8)\n",
    "Y = []\n",
    "path = 'cifar-10-batches-py//'\n",
    "\n",
    "for i in range(1, 6):\n",
    "    p = pickle.load(open(path + 'data_batch_' + str(i), 'rb'), encoding='bytes')\n",
    "    data = p[b'data']\n",
    "    labels = p[b'labels']\n",
    "    data = data.reshape(10000, 3, 32, 32)\n",
    "    data = np.transpose(data, (0, 2, 3, 1))\n",
    "    \n",
    "    # Append data\n",
    "    X[(i - 1) * 10000 : i * 10000] = data\n",
    "    \n",
    "    # Concat labels\n",
    "    Y += labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), 50000)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2baed474be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check a random img and it's label\n",
    "mapping = {0:'airplane', \n",
    "           1:'automobile', \n",
    "           2:'bird', \n",
    "           3:'cat', \n",
    "           4:'deer', \n",
    "           5:'dog', \n",
    "           6:'frog', \n",
    "           7:'horse', \n",
    "           8:'ship', \n",
    "           9:'truck'}\n",
    "rid = np.random.choice(range(50000))\n",
    "img = X_norm[rid]\n",
    "l = Y[rid]\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(mapping[l])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 对像素灰度值进行归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_norm = (X - np.min(X)) / (np.max(X) - np.min(X))\n",
    "X_norm = X_norm.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 59,  43,  50,  68,  98],\n",
       "       [ 16,   0,  18,  51,  88],\n",
       "       [ 25,  16,  49,  83, 110],\n",
       "       [ 33,  38,  87, 106, 115],\n",
       "       [ 50,  59, 102, 127, 124]], dtype=uint8)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对比归一化后同一张图片相同区域像素点的取值变化\n",
    "X[0, :5, :5, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.23137255,  0.16862746,  0.19607843,  0.26666668,  0.38431373],\n",
       "       [ 0.0627451 ,  0.        ,  0.07058824,  0.2       ,  0.34509805],\n",
       "       [ 0.09803922,  0.0627451 ,  0.19215687,  0.32549021,  0.43137255],\n",
       "       [ 0.12941177,  0.14901961,  0.34117648,  0.41568628,  0.4509804 ],\n",
       "       [ 0.19607843,  0.23137255,  0.40000001,  0.49803922,  0.48627451]], dtype=float32)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_norm[0, :5, :5, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146.48451232910156, 585.9376373291016)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 由于元素类型从 uint8 变成 float32，因此占用空间增大很多\n",
    "sys.getsizeof(X)/1024/1024, sys.getsizeof(X_norm)/1024/1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 对标签进行 One-Hot 编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "# 按照数字顺序进行映射，如果直接 fit_transform 的话映射顺序取决于样本中类型的出现顺序\n",
    "lb.fit(range(10)) \n",
    "Y_onehot = lb.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (50000, 10), 6, array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0]))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Y_onehot), Y_onehot.shape, Y[0], Y_onehot[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 导出预处理后的训练数据\n",
    "\n",
    "- 将训练数据输出为含有 4 个元素的 Tuple\n",
    "    - 前两个是训练集图像及其标签，含有 45000 张图片\n",
    "    - 后两个是验证集图像及其标签，含有 5000  张图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump((X_norm[:45000], Y_onehot[:45000], \n",
    "             X_norm[45000:], Y_onehot[45000:],), \n",
    "            open('CIFAR10 Preprocessed', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第二章 CIFAR10 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 载入预处理后的训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Dimension:  (45000, 32, 32, 3)\n",
      "Y_train Dimension (45000, 10)\n",
      "X_test Dimension:  (5000, 32, 32, 3)\n",
      "Y_test Dimension (5000, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = pickle.load(open('CIFAR10 Preprocessed', mode='rb'))\n",
    "print(\"X_train Dimension: \", X_train.shape)\n",
    "print(\"Y_train Dimension\", Y_train.shape)\n",
    "print(\"X_test Dimension: \", X_test.shape)\n",
    "print(\"Y_test Dimension\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 计算卷积层的输出尺寸\n",
    "\n",
    "- 卷积层输出的矩阵尺寸由三个因素决定：\n",
    "    - 输入矩阵尺寸\n",
    "    - 卷积核尺寸\n",
    "    - 步长\n",
    "    \n",
    "\n",
    "- 计算公式为\n",
    "\n",
    "$$\\mathrm{output = (input - kernel + 2 * padding) ~ / ~ stride + 1}$$\n",
    "\n",
    "下面用指针的思路写了一个推测输出形状的函数，比计算公式好理解。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape =  (32, 32, 3)\n",
      "Output Shape =  (15, 15, 64)\n"
     ]
    }
   ],
   "source": [
    "# 假设输入图片和卷积核的形状都是正方形\n",
    "def get_output_shape(input_shape, kernel_shape, stride):\n",
    "    j = kernel_shape - 1\n",
    "    c = 0\n",
    "    while j < input_shape:\n",
    "        c += 1\n",
    "        j += stride\n",
    "    return c\n",
    "\n",
    "# 假设图片尺寸为 32 x 32 x 3，卷积核尺寸为 3 x 3 x 3，步长为 2，卷积核个数 64\n",
    "n_kernel = 64\n",
    "input_shape = 32\n",
    "output_shape = get_output_shape(32, 3, 2)\n",
    "print('Input Shape = ', (input_shape, input_shape, 3))\n",
    "print('Output Shape = ', (output_shape, output_shape, n_kernel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 构造模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 模型由以下几层组合而成\n",
    "    - **卷积层**：用卷积核与每个图像进行卷积计算，输出特征图（Feature map），图像的深度得到扩展。\n",
    "    - **池化层**：挑选取值最大的像素点作为代表，主要意义是降维（降低图像尺寸）\n",
    "    - **展开层**：将三维的图像数据拉直为一维向量，向量的每个元素被视为一个特征，方便送入全连接层。\n",
    "    - **全连接层**：特征的非线性分类器，与 MLP 中的全链接层功能一样。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.layers.conv2d\n",
    "> tf.layers.conv2d(inputs, filters, kernel_size, strides=(1, 1), padding='valid', data_format='channels_last', dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer=None, bias_initializer=?, kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, trainable=True, name=None, reuse=None)\n",
    "\n",
    "### tf.nn.conv2d\n",
    "\n",
    "> tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, data_format=None, name=None)\n",
    "\n",
    "conv2d 是一个 operation，要求输入的 input 和 filter 本身都是 Tensor 类型的对象，因此需要先用 `tf.Variable` 定义这两个对象，并且对权重矩阵这个 Tensor 进行初始化才能调用 conv2d 函数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_layer(x, out_channel, k_size, stride, padding):\n",
    "    in_channel = x.shape[3].value\n",
    "    w = tf.Variable(tf.truncated_normal([k_size, k_size, in_channel, out_channel], mean=0, stddev=stddev))\n",
    "    b = tf.Variable(tf.zeros(out_channel))\n",
    "    x = tf.nn.conv2d(x, filter=w, strides=[1, stride, stride, 1], padding=padding)\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    x = tf.nn.relu(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def pool_layer(x, k_size, stride, padding):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k_size, k_size, 1], strides=[1, stride, stride, 1], padding=padding)\n",
    "\n",
    "\n",
    "def flatten_layer(x):\n",
    "    dim = x.shape[1].value * x.shape[2].value * x.shape[3].value\n",
    "    return tf.reshape(x, shape=[-1, dim])\n",
    "\n",
    "\n",
    "def fc_layer(x, n_output):\n",
    "    w = tf.Variable(tf.truncated_normal([x.shape[1].value, n_output], mean=0, stddev=stddev))\n",
    "    b = tf.Variable(tf.zeros(n_output))\n",
    "    x = tf.matmul(x, w)\n",
    "    x = tf.add(x, b)\n",
    "    x = tf.nn.relu(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def dropout_layer(x, keep_prob):\n",
    "    return tf.nn.dropout(x, keep_prob)\n",
    "\n",
    "\n",
    "def output_layer(x, n_output):\n",
    "    w = tf.Variable(tf.truncated_normal([x.shape[1].value, n_output], mean=0, stddev=stddev))\n",
    "    b = tf.Variable(tf.zeros(n_output))\n",
    "    x = tf.matmul(x, w)\n",
    "    x = tf.add(x, b)\n",
    "    x = tf.identity(x, name='logits')  # Rename\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_model(x, keep_prob):\n",
    "#     x = conv_layer(x, 16, 3, 1, 'SAME')\n",
    "#     x = pool_layer(x, 2, 1, 'SAME')\n",
    "#     x = conv_layer(x, 32, 3, 1, 'SAME')\n",
    "#     x = pool_layer(x, 2, 1, 'SAME')\n",
    "#     x = flatten_layer(x)\n",
    "#     x = fc_layer(x, 1024)\n",
    "#     x = dropout_layer(x, keep_prob)\n",
    "#     x = output_layer(x, 10)\n",
    "\n",
    "    x = tf.contrib.layers.conv2d(x, 16, 3, 1, 'SAME', weights_regularizer=tf.contrib.layers.l2_regularizer(0.1))\n",
    "    x = tf.contrib.layers.batch_norm(x)\n",
    "    x = tf.nn.max_pool(x, [1, 2, 2, 1], [1, 1, 1, 1], 'SAME')\n",
    "    x = tf.contrib.layers.conv2d(x, 16, 3, 1, 'SAME', weights_regularizer=tf.contrib.layers.l2_regularizer(0.1))\n",
    "    x = tf.contrib.layers.batch_norm(x)\n",
    "    x = tf.nn.max_pool(x, [1, 2, 2, 1], [1, 1, 1, 1], 'SAME')\n",
    "    x = tf.contrib.layers.conv2d(x, 16, 3, 1, 'SAME', weights_regularizer=tf.contrib.layers.l2_regularizer(0.1))\n",
    "    x = tf.contrib.layers.batch_norm(x)\n",
    "    x = tf.nn.max_pool(x, [1, 2, 2, 1], [1, 1, 1, 1], 'SAME')\n",
    "    x = tf.contrib.layers.flatten(x)\n",
    "    x = tf.contrib.layers.fully_connected(x, 1024, activation_fn=tf.nn.relu)\n",
    "    x = tf.nn.dropout(x, keep_prob)\n",
    "    x = tf.contrib.layers.fully_connected(x, 10, activation_fn=None)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 建立计算图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_class = 10\n",
    "batch_size = 256\n",
    "stddev = 0.01\n",
    "epoch = 100\n",
    "dropout = 0.25\n",
    "\n",
    "tf.reset_default_graph()\n",
    "x_input   = tf.placeholder(tf.float32, shape=(None, 32, 32, 3), name='x_input')\n",
    "y_true    = tf.placeholder(tf.float32, shape=(None, n_class), name='y_true')\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "y_pred = create_model(x_input, keep_prob)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pred, labels=y_true))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "correct_pred = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))    \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 数据生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch(x, y, batch_size):\n",
    "    for start in range(0, len(x), batch_size):\n",
    "        end = min(start + batch_size, len(x))\n",
    "        yield x[start:end], y[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 用 Session 执行运算图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0     train_loss = 1.46009      train_acc = 43.5 %      validation_acc = 47.04 %\n",
      "Epoch = 1     train_loss = 1.3301      train_acc = 55.5 %      validation_acc = 54.08 %\n",
      "Epoch = 2     train_loss = 1.22888      train_acc = 50.5 %      validation_acc = 56.94 %\n",
      "Epoch = 3     train_loss = 1.1822      train_acc = 53.5 %      validation_acc = 59.76 %\n",
      "Epoch = 4     train_loss = 1.1254      train_acc = 61.5 %      validation_acc = 61.02 %\n",
      "Epoch = 5     train_loss = 1.08046      train_acc = 61.5 %      validation_acc = 62.14 %\n",
      "Epoch = 6     train_loss = 1.08316      train_acc = 62.5 %      validation_acc = 62.94 %\n",
      "Epoch = 7     train_loss = 1.00017      train_acc = 63.5 %      validation_acc = 64.54 %\n",
      "Epoch = 8     train_loss = 0.97191      train_acc = 65.0 %      validation_acc = 65.84 %\n",
      "Epoch = 9     train_loss = 0.917604      train_acc = 67.5 %      validation_acc = 65.98 %\n",
      "Epoch = 10     train_loss = 0.880607      train_acc = 69.0 %      validation_acc = 66.5 %\n",
      "Epoch = 11     train_loss = 0.810764      train_acc = 68.5 %      validation_acc = 67.04 %\n",
      "Epoch = 12     train_loss = 0.76811      train_acc = 71.5 %      validation_acc = 67.28 %\n",
      "Epoch = 13     train_loss = 0.767998      train_acc = 72.0 %      validation_acc = 68.26 %\n",
      "Epoch = 14     train_loss = 0.761557      train_acc = 72.0 %      validation_acc = 67.54 %\n",
      "Epoch = 15     train_loss = 0.725352      train_acc = 74.5 %      validation_acc = 67.88 %\n",
      "Epoch = 16     train_loss = 0.671638      train_acc = 77.5 %      validation_acc = 67.94 %\n",
      "Epoch = 17     train_loss = 0.655912      train_acc = 78.5 %      validation_acc = 68.38 %\n",
      "Epoch = 18     train_loss = 0.635038      train_acc = 76.5 %      validation_acc = 68.82 %\n",
      "Epoch = 19     train_loss = 0.635711      train_acc = 77.0 %      validation_acc = 68.56 %\n",
      "Epoch = 20     train_loss = 0.621933      train_acc = 78.5 %      validation_acc = 69.1 %\n",
      "Epoch = 21     train_loss = 0.636581      train_acc = 79.0 %      validation_acc = 69.14 %\n",
      "Epoch = 22     train_loss = 0.566627      train_acc = 82.0 %      validation_acc = 69.06 %\n",
      "Epoch = 23     train_loss = 0.591299      train_acc = 79.5 %      validation_acc = 69.16 %\n",
      "Epoch = 24     train_loss = 0.575545      train_acc = 77.5 %      validation_acc = 68.82 %\n",
      "Epoch = 25     train_loss = 0.585149      train_acc = 79.0 %      validation_acc = 69.68 %\n",
      "Epoch = 26     train_loss = 0.518235      train_acc = 83.5 %      validation_acc = 69.58 %\n",
      "Epoch = 27     train_loss = 0.56903      train_acc = 79.0 %      validation_acc = 69.22 %\n",
      "Epoch = 28     train_loss = 0.549365      train_acc = 84.0 %      validation_acc = 68.26 %\n",
      "Epoch = 29     train_loss = 0.556909      train_acc = 79.0 %      validation_acc = 69.42 %\n",
      "Epoch = 30     train_loss = 0.493078      train_acc = 84.0 %      validation_acc = 69.0 %\n",
      "Epoch = 31     train_loss = 0.459989      train_acc = 87.5 %      validation_acc = 68.76 %\n",
      "Epoch = 32     train_loss = 0.464481      train_acc = 83.5 %      validation_acc = 69.4 %\n",
      "Epoch = 33     train_loss = 0.452571      train_acc = 86.0 %      validation_acc = 69.02 %\n",
      "Epoch = 34     train_loss = 0.435843      train_acc = 88.0 %      validation_acc = 68.82 %\n",
      "Epoch = 35     train_loss = 0.42287      train_acc = 86.0 %      validation_acc = 69.52 %\n",
      "Epoch = 36     train_loss = 0.427858      train_acc = 86.5 %      validation_acc = 68.72 %\n",
      "Epoch = 37     train_loss = 0.418096      train_acc = 87.5 %      validation_acc = 68.98 %\n",
      "Epoch = 38     train_loss = 0.407322      train_acc = 84.0 %      validation_acc = 69.98 %\n",
      "Epoch = 39     train_loss = 0.382151      train_acc = 88.0 %      validation_acc = 69.38 %\n",
      "Epoch = 40     train_loss = 0.401937      train_acc = 86.5 %      validation_acc = 69.96 %\n",
      "Epoch = 41     train_loss = 0.368786      train_acc = 89.5 %      validation_acc = 69.7 %\n",
      "Epoch = 42     train_loss = 0.356417      train_acc = 89.5 %      validation_acc = 69.84 %\n",
      "Epoch = 43     train_loss = 0.376955      train_acc = 88.5 %      validation_acc = 69.46 %\n",
      "Epoch = 44     train_loss = 0.333556      train_acc = 90.0 %      validation_acc = 70.28 %\n",
      "Epoch = 45     train_loss = 0.353189      train_acc = 89.5 %      validation_acc = 69.72 %\n",
      "Epoch = 46     train_loss = 0.351358      train_acc = 92.0 %      validation_acc = 69.24 %\n",
      "Epoch = 47     train_loss = 0.330801      train_acc = 89.5 %      validation_acc = 70.66 %\n",
      "Epoch = 48     train_loss = 0.331311      train_acc = 89.5 %      validation_acc = 69.82 %\n",
      "Epoch = 49     train_loss = 0.364724      train_acc = 89.0 %      validation_acc = 69.92 %\n",
      "Epoch = 50     train_loss = 0.335801      train_acc = 88.0 %      validation_acc = 70.08 %\n",
      "Epoch = 51     train_loss = 0.327155      train_acc = 89.5 %      validation_acc = 69.38 %\n",
      "Epoch = 52     train_loss = 0.325166      train_acc = 87.0 %      validation_acc = 69.82 %\n",
      "Epoch = 53     train_loss = 0.3058      train_acc = 90.0 %      validation_acc = 69.7 %\n",
      "Epoch = 54     train_loss = 0.317115      train_acc = 91.0 %      validation_acc = 69.88 %\n",
      "Epoch = 55     train_loss = 0.29068      train_acc = 91.5 %      validation_acc = 69.56 %\n",
      "Epoch = 56     train_loss = 0.300987      train_acc = 89.5 %      validation_acc = 69.4 %\n",
      "Epoch = 57     train_loss = 0.272007      train_acc = 91.5 %      validation_acc = 69.88 %\n",
      "Epoch = 58     train_loss = 0.277335      train_acc = 92.0 %      validation_acc = 70.14 %\n",
      "Epoch = 59     train_loss = 0.276391      train_acc = 92.0 %      validation_acc = 70.18 %\n",
      "Epoch = 60     train_loss = 0.279736      train_acc = 90.0 %      validation_acc = 70.34 %\n",
      "Epoch = 61     train_loss = 0.263522      train_acc = 91.0 %      validation_acc = 70.06 %\n",
      "Epoch = 62     train_loss = 0.283775      train_acc = 90.5 %      validation_acc = 70.26 %\n",
      "Epoch = 63     train_loss = 0.265379      train_acc = 90.0 %      validation_acc = 69.9 %\n",
      "Epoch = 64     train_loss = 0.267992      train_acc = 91.0 %      validation_acc = 69.88 %\n",
      "Epoch = 65     train_loss = 0.272847      train_acc = 91.0 %      validation_acc = 70.3 %\n",
      "Epoch = 66     train_loss = 0.287681      train_acc = 90.5 %      validation_acc = 70.56 %\n",
      "Epoch = 67     train_loss = 0.249603      train_acc = 92.0 %      validation_acc = 70.44 %\n",
      "Epoch = 68     train_loss = 0.277034      train_acc = 91.0 %      validation_acc = 70.48 %\n",
      "Epoch = 69     train_loss = 0.24593      train_acc = 93.0 %      validation_acc = 70.08 %\n",
      "Epoch = 70     train_loss = 0.273444      train_acc = 93.0 %      validation_acc = 69.64 %\n",
      "Epoch = 71     train_loss = 0.30862      train_acc = 93.5 %      validation_acc = 69.96 %\n",
      "Epoch = 72     train_loss = 0.291507      train_acc = 92.0 %      validation_acc = 70.66 %\n",
      "Epoch = 73     train_loss = 0.239405      train_acc = 94.5 %      validation_acc = 70.5 %\n",
      "Epoch = 74     train_loss = 0.231459      train_acc = 92.5 %      validation_acc = 70.8 %\n",
      "Epoch = 75     train_loss = 0.226743      train_acc = 93.5 %      validation_acc = 69.32 %\n",
      "Epoch = 76     train_loss = 0.239362      train_acc = 94.0 %      validation_acc = 70.04 %\n",
      "Epoch = 77     train_loss = 0.241239      train_acc = 92.5 %      validation_acc = 69.98 %\n",
      "Epoch = 78     train_loss = 0.238925      train_acc = 93.0 %      validation_acc = 69.84 %\n",
      "Epoch = 79     train_loss = 0.235685      train_acc = 91.5 %      validation_acc = 69.78 %\n",
      "Epoch = 80     train_loss = 0.244013      train_acc = 92.5 %      validation_acc = 69.88 %\n",
      "Epoch = 81     train_loss = 0.237303      train_acc = 92.0 %      validation_acc = 70.06 %\n",
      "Epoch = 82     train_loss = 0.232272      train_acc = 93.5 %      validation_acc = 69.9 %\n",
      "Epoch = 83     train_loss = 0.24721      train_acc = 93.5 %      validation_acc = 69.46 %\n",
      "Epoch = 84     train_loss = 0.250007      train_acc = 91.0 %      validation_acc = 70.08 %\n",
      "Epoch = 85     train_loss = 0.210993      train_acc = 94.5 %      validation_acc = 69.44 %\n",
      "Epoch = 86     train_loss = 0.19311      train_acc = 95.0 %      validation_acc = 69.8 %\n",
      "Epoch = 87     train_loss = 0.220451      train_acc = 93.5 %      validation_acc = 69.2 %\n",
      "Epoch = 88     train_loss = 0.219891      train_acc = 95.0 %      validation_acc = 69.56 %\n",
      "Epoch = 89     train_loss = 0.214597      train_acc = 94.0 %      validation_acc = 70.26 %\n",
      "Epoch = 90     train_loss = 0.191108      train_acc = 94.0 %      validation_acc = 71.04 %\n",
      "Epoch = 91     train_loss = 0.216638      train_acc = 94.0 %      validation_acc = 70.0 %\n",
      "Epoch = 92     train_loss = 0.216347      train_acc = 92.0 %      validation_acc = 69.54 %\n",
      "Epoch = 93     train_loss = 0.2      train_acc = 95.0 %      validation_acc = 70.04 %\n",
      "Epoch = 94     train_loss = 0.212424      train_acc = 92.0 %      validation_acc = 69.76 %\n",
      "Epoch = 95     train_loss = 0.195728      train_acc = 94.0 %      validation_acc = 69.92 %\n",
      "Epoch = 96     train_loss = 0.205914      train_acc = 93.0 %      validation_acc = 70.22 %\n",
      "Epoch = 97     train_loss = 0.195489      train_acc = 94.5 %      validation_acc = 69.84 %\n",
      "Epoch = 98     train_loss = 0.20496      train_acc = 93.0 %      validation_acc = 69.84 %\n",
      "Epoch = 99     train_loss = 0.188515      train_acc = 94.5 %      validation_acc = 69.2 %\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as session:\n",
    "    # 可视化整个网络结构的视图，通过 TensorBoard 查看\n",
    "    tf.summary.FileWriter('./graphs', session.graph)\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    for i in range(epoch):\n",
    "        # 将训练集按 batch_size 切分为很多 batch，每个 batch 用于更新一次模型参数\n",
    "        for X_batch, Y_batch in get_batch(X_train, Y_train, batch_size):\n",
    "            session.run(optimizer, feed_dict={x_input:X_batch, y_true:Y_batch, keep_prob:dropout})\n",
    "        \n",
    "        # 本轮训练集（45000张图片）最后一个 batch 的损失值\n",
    "        loss = session.run(cost, feed_dict={x_input:X_batch, y_true:Y_batch, keep_prob:1})\n",
    "        \n",
    "        # 本轮训练后的模型用于训练集的最后一个 batch 的准确率\n",
    "        acc = session.run(accuracy, feed_dict={x_input:X_batch, y_true:Y_batch, keep_prob:1})\n",
    "        \n",
    "        # 本轮训练后的模型用于验证集（5000张图片）的准确率\n",
    "        val_acc = session.run(accuracy, feed_dict={x_input:X_test, y_true:Y_test, keep_prob:1})\n",
    "        \n",
    "        print(\"Epoch =\", i, \"    train_loss =\", loss, \n",
    "              \"     train_acc =\", round(acc * 100, 2), \"%\", \n",
    "              \"     validation_acc =\", round(val_acc * 100, 2), \"%\")\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(session, '.\\michael')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "带BatchNorm和L2正则的三层卷积模型在CIFAR10数据集上的最终准确率为70%左右。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Couple of tips:\n",
    "- make sure you do Xavier initialization (check that you use the correct parameters depending upon your activation function);\n",
    "- make sure you are using ReLU (but try Leaky ReLU as well) as your activation function - or possibly ELU;\n",
    "- implement batch normalization prior to fully connected layers (its often useful in other layers);\n",
    "- make sure you've implemented dropout;\n",
    "- test out a different regularization and dropout parameters;\n",
    "- building an ensemble might net you an additional 1-2% (do this at the end)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
